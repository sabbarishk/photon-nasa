# {{ title }}
# NASA Dataset Analysis & Visualization
# Dataset: {{ dataset_url }}
# Variable: {{ variable }}

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

plt.style.use('seaborn-v0_8-darkgrid')
plt.rcParams['figure.figsize'] = (14, 10)
plt.rcParams['font.size'] = 11

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# STEP 1: Load Data
# STEP 1: Load Data
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ðŸ“Š Loading NASA dataset...")
url = "{{ dataset_url }}"

df = None

# Strategy 1 â€“ standard CSV
try:
    df = pd.read_csv(url)
    if isinstance(df.index, pd.MultiIndex):
        col_names = list(df.index[0])
        data_rows = [list(idx) for idx in df.index[1:]]
        df = pd.DataFrame(data_rows, columns=col_names)
    print(f"âœ… Loaded {len(df)} rows, {len(df.columns)} columns (standard)")
except Exception:
    pass

# Strategy 2 â€“ skip comment/header rows
if df is None or df.empty:
    for skip in [1, 2, 3, 5, 7]:
        try:
            df = pd.read_csv(url, skiprows=skip)
            if not df.empty:
                print(f"âœ… Loaded {len(df)} rows (skiprows={skip})")
                break
        except Exception:
            pass

# Strategy 3 â€“ skip bad lines
if df is None or df.empty:
    try:
        df = pd.read_csv(url, on_bad_lines='skip', engine='python')
        print(f"âœ… Loaded {len(df)} rows (bad-lines skipped)")
    except Exception:
        pass

# Strategy 4 â€“ whitespace / tab separator
if df is None or df.empty:
    for sep in ['\t', r'\s+', '|', ';']:
        try:
            df = pd.read_csv(url, sep=sep, engine='python')
            if not df.empty and len(df.columns) > 1:
                print(f"âœ… Loaded {len(df)} rows (sep={repr(sep)})")
                break
        except Exception:
            pass

# Strategy 5 â€“ skip rows + bad-lines together
if df is None or df.empty:
    for skip in range(1, 15):
        try:
            df = pd.read_csv(url, skiprows=skip, on_bad_lines='skip', engine='python')
            if not df.empty and len(df.columns) > 1:
                print(f"âœ… Loaded {len(df)} rows (skiprows={skip} + bad-lines skipped)")
                break
        except Exception:
            pass

# Strategy 6 â€“ read raw lines, find where data starts
if df is None or df.empty:
    try:
        import urllib.request
        from io import StringIO
        with urllib.request.urlopen(url, timeout=30) as resp:
            raw = resp.read().decode('utf-8', errors='replace')
        lines = [l for l in raw.splitlines() if l.strip() and not l.strip().startswith(('#', '%', '!'))]
        if lines:
            df = pd.read_csv(StringIO('\n'.join(lines)), on_bad_lines='skip', engine='python')
            print(f"âœ… Loaded {len(df)} rows (raw line filtering)")
    except Exception:
        pass

# Give up gracefully
if df is None or df.empty:
    print("""
âŒ Could not parse dataset.

Possible reasons:
  â€¢ URL points to a landing page rather than a raw data file
  â€¢ File requires authentication or is not publicly accessible
  â€¢ Format is NetCDF / HDF5 (choose the matching format in the generator)
  â€¢ Network error

Please verify the dataset URL is a direct link to a CSV/text file.
""")
    raise SystemExit(1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# STEP 2: Clean & Detect Columns
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df.columns = [str(c).strip() for c in df.columns]
df.dropna(how='all', axis=1, inplace=True)

print(f"\nðŸ“‹ Dataset shape: {df.shape}")
print(f"Columns: {list(df.columns)[:8]}{'...' if len(df.columns) > 8 else ''}")
print(df.head(3).to_string())

# Detect time / year column
time_col = None
for c in df.columns:
    cl = c.lower()
    if any(k in cl for k in ['year', 'date', 'time', 'month', 'day']):
        time_col = c
        break

# Convert all non-time columns to numeric
for c in df.columns:
    df[c] = pd.to_numeric(df[c], errors='coerce')

df.dropna(how='all', subset=[c for c in df.columns if c != time_col], inplace=True)
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

variable = "{{ variable }}".strip()
if variable in df.columns:
    data_col = variable
elif len(numeric_cols) > 0:
    candidates = [c for c in numeric_cols if c != time_col]
    data_col = candidates[0] if candidates else numeric_cols[0]
    print(f"âš ï¸  Variable '{variable}' not found â€“ using '{data_col}'")
else:
    print("âŒ No numeric data found.")
    raise SystemExit(1)

# Build x/y arrays
if time_col and time_col in df.columns:
    clean = df[[time_col, data_col]].dropna()
    x_vals = clean[time_col].values.astype(float)
    y_vals = clean[data_col].values.astype(float)
    x_label = time_col
else:
    clean = df[[data_col]].dropna()
    y_vals = clean[data_col].values.astype(float)
    x_vals = np.arange(len(y_vals), dtype=float)
    x_label = "Index"

print(f"\nâœ… {len(y_vals)} data points for '{data_col}'")
print(f"   Range: {y_vals.min():.4f} â†’ {y_vals.max():.4f}  |  Mean: {y_vals.mean():.4f}  |  Std: {y_vals.std():.4f}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# STEP 3: Visualise
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig, axes = plt.subplots(2, 3, figsize=(18, 11))
fig.suptitle("{{ title }}", fontsize=17, fontweight='bold', y=0.99)

# Plot 1: Time series
ax = axes[0, 0]
ax.plot(x_vals, y_vals, lw=1.8, color='#2E86AB', alpha=0.85, marker='o', markersize=2.5)
if len(y_vals) > 2:
    z = np.polyfit(x_vals, y_vals, 1)
    p = np.poly1d(z)
    ax.plot(x_vals, p(x_vals), '--', color='#C73E1D', lw=2, label=f'Trend: {z[0]:+.4f}/unit')
    ax.legend(fontsize=9)
ax.set_title(f"{data_col} over {x_label}", fontweight='bold')
ax.set_xlabel(x_label); ax.set_ylabel(data_col)
ax.grid(True, alpha=0.3)

# Plot 2: Histogram
ax = axes[0, 1]
ax.hist(y_vals, bins=min(30, max(10, len(y_vals)//5)),
        color='#F18F01', edgecolor='white', alpha=0.8)
try:
    from scipy.stats import gaussian_kde
    kde_x = np.linspace(y_vals.min(), y_vals.max(), 300)
    kde = gaussian_kde(y_vals)
    ax2_twin = ax.twinx()
    ax2_twin.plot(kde_x, kde(kde_x), color='#C73E1D', lw=2, label='KDE')
    ax2_twin.set_ylabel('Density')
    ax2_twin.legend(loc='upper right', fontsize=9)
except Exception:
    pass
ax.set_title("Distribution", fontweight='bold')
ax.set_xlabel(data_col); ax.set_ylabel("Count")
ax.grid(True, alpha=0.3, axis='y')

# Plot 3: Box plot
ax = axes[0, 2]
ax.boxplot(y_vals, vert=True, patch_artist=True,
           boxprops=dict(facecolor='#84DCC6', alpha=0.7),
           medianprops=dict(color='#C73E1D', lw=2))
stats_txt = (f"Mean:   {np.mean(y_vals):.3f}\n"
             f"Median: {np.median(y_vals):.3f}\n"
             f"Std:    {np.std(y_vals):.3f}\n"
             f"Min:    {np.min(y_vals):.3f}\n"
             f"Max:    {np.max(y_vals):.3f}")
ax.text(1.35, np.median(y_vals), stats_txt, fontsize=9,
        va='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.6))
ax.set_title("Box Plot", fontweight='bold')
ax.set_ylabel(data_col); ax.grid(True, alpha=0.3, axis='y')

# Plot 4: Rolling mean
ax = axes[1, 0]
ax.plot(x_vals, y_vals, 'o-', alpha=0.25, ms=2, color='gray', label='Raw')
if len(y_vals) > 10:
    win = max(5, len(y_vals) // 15)
    roll = pd.Series(y_vals).rolling(win, center=True)
    rm = roll.mean().values
    rs = roll.std().values
    ax.plot(x_vals, rm, lw=2, color='#2E86AB', label=f'{win}-pt avg')
    ax.fill_between(x_vals, rm - rs, rm + rs, alpha=0.2, color='#F18F01', label='Â±1Ïƒ')
ax.legend(fontsize=9)
ax.set_title("Rolling Statistics", fontweight='bold')
ax.set_xlabel(x_label); ax.set_ylabel(data_col); ax.grid(True, alpha=0.3)

# Plot 5: Anomaly bars
ax = axes[1, 1]
mean_val = np.mean(y_vals)
anomaly = y_vals - mean_val
bar_colors = ['#C73E1D' if a > 0 else '#2E86AB' for a in anomaly]
bar_width = max(0.6, (x_vals[-1] - x_vals[0]) / max(len(x_vals), 1) * 0.9) if len(x_vals) > 1 else 0.6
ax.bar(x_vals, anomaly, color=bar_colors, alpha=0.7, width=bar_width)
ax.axhline(0, color='black', lw=0.8)
ax.set_title(f"Anomaly (baseline = {mean_val:.3f})", fontweight='bold')
ax.set_xlabel(x_label); ax.set_ylabel(f"{data_col} anomaly"); ax.grid(True, alpha=0.3, axis='y')

# Plot 6: Correlation heatmap OR period-change bars
ax = axes[1, 2]
num_candidates = [c for c in numeric_cols if c != time_col]
if len(num_candidates) >= 2:
    try:
        import seaborn as sns
        corr = df[num_candidates[:8]].corr()
        sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0,
                    square=True, ax=ax, cbar_kws={'shrink': 0.8}, annot_kws={'size': 8})
        ax.set_title("Correlation Matrix", fontweight='bold')
    except Exception:
        ax.axis('off')
        ax.text(0.5, 0.5, f"Dataset: {len(y_vals)} points\n{data_col}\nMean: {mean_val:.4f}",
                ha='center', va='center', fontsize=12, transform=ax.transAxes)
        ax.set_title("Summary", fontweight='bold')
elif len(y_vals) > 2:
    dy = np.diff(y_vals)
    ax.bar(x_vals[1:], dy, color=['#84DCC6' if v >= 0 else '#C73E1D' for v in dy], alpha=0.7)
    ax.axhline(0, color='black', lw=0.8)
    ax.set_title(f"Period-over-Period Î”{data_col}", fontweight='bold')
    ax.set_xlabel(x_label); ax.set_ylabel(f"Î”{data_col}"); ax.grid(True, alpha=0.3, axis='y')
else:
    ax.axis('off')
    ax.set_title("Summary", fontweight='bold')

plt.tight_layout()
plt.show()

print("\nâœ… Analysis complete!")
print(f"   Dataset  : {{ dataset_url }}")
print(f"   Variable : {data_col}")
print(f"   Points   : {len(y_vals)}")
print(f"   Mean     : {np.mean(y_vals):.4f}")
print(f"   Std      : {np.std(y_vals):.4f}")
print(f"   Range    : [{np.min(y_vals):.4f}, {np.max(y_vals):.4f}]")
